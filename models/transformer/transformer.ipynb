{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"transformer.ipynb","provenance":[],"include_colab_link":true},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9507939,"sourceType":"datasetVersion","datasetId":5787145},{"sourceId":197056,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":168047,"modelId":190386}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip -q install torchtext==0.6.0\n! pip -q install pyvi \n! pip -q install https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz\n! python -m spacy link vi_spacy_model vi_spacy_model\n! pip install rouge-score nltk datasets\nimport nltk\nnltk.download('wordnet')","metadata":{"id":"RVOKeezWPsSs","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:12.153710Z","iopub.execute_input":"2024-12-13T09:39:12.154532Z","iopub.status.idle":"2024-12-13T09:39:39.772891Z","shell.execute_reply.started":"2024-12-13T09:39:12.154494Z","shell.execute_reply":"2024-12-13T09:39:39.771879Z"}},"outputs":[{"name":"stdout","text":"\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not install requirement https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz because of HTTP error 404 Client Error: Not Found for url: https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz for URL https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mDeprecationWarning: The command 'link' is deprecated.\u001b[0m\n\u001b[38;5;3m⚠ As of spaCy v3.0, model symlinks are not supported anymore. You can\nload trained pipeline packages using their full names or from a directory\npath.\u001b[0m\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\nimport os\nimport math\nfrom rouge_score import rouge_scorer","metadata":{"id":"8gvN64qvNQIS","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:39.775002Z","iopub.execute_input":"2024-12-13T09:39:39.775886Z","iopub.status.idle":"2024-12-13T09:39:41.324442Z","shell.execute_reply.started":"2024-12-13T09:39:39.775845Z","shell.execute_reply":"2024-12-13T09:39:41.323756Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Embedder(nn.Module):\n    def __init__(self, vocab_size, d_model):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.d_model = d_model\n        \n        self.embed = nn.Embedding(vocab_size, d_model)\n        \n    def forward(self, x):\n        return self.embed(x)\n    \n# Embedder(100, 512)(torch.LongTensor([1,2,3,4])).shape","metadata":{"id":"X9da_ZuSNQIW","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.325478Z","iopub.execute_input":"2024-12-13T09:39:41.325910Z","iopub.status.idle":"2024-12-13T09:39:41.331472Z","shell.execute_reply.started":"2024-12-13T09:39:41.325871Z","shell.execute_reply":"2024-12-13T09:39:41.330679Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PositionalEncoder(nn.Module):\n    def __init__(self, d_model, max_seq_length=200, dropout=0.1):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.dropout = nn.Dropout(dropout)\n        \n        pe = torch.zeros(max_seq_length, d_model)\n        \n        # Bảng pe mình vẽ ở trên \n        for pos in range(max_seq_length):\n            for i in range(0, d_model, 2):\n                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n                pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n        pe = pe.unsqueeze(0)        \n        self.register_buffer('pe', pe)\n    \n    def forward(self, x):\n        \n        x = x*math.sqrt(self.d_model)\n        seq_length = x.size(1)\n        \n        pe = Variable(self.pe[:, :seq_length], requires_grad=False)\n        \n        if x.is_cuda:\n            pe.cuda()\n        # cộng embedding vector với pe \n        x = x + pe\n        x = self.dropout(x)\n        \n        return x\n    \n# PositionalEncoder(512)(torch.rand(5, 30, 512)).shape","metadata":{"id":"rP64KizDNQIa","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.332670Z","iopub.execute_input":"2024-12-13T09:39:41.333045Z","iopub.status.idle":"2024-12-13T09:39:41.344237Z","shell.execute_reply.started":"2024-12-13T09:39:41.332989Z","shell.execute_reply":"2024-12-13T09:39:41.343427Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def attention(q, k, v, mask=None, dropout=None):\n    \"\"\"\n    q: batch_size x head x seq_length x d_model\n    k: batch_size x head x seq_length x d_model\n    v: batch_size x head x seq_length x d_model\n    mask: batch_size x 1 x 1 x seq_length\n    output: batch_size x head x seq_length x d_model\n    \"\"\"\n\n    # attention score được tính bằng cách nhân q với k\n    d_k = q.size(-1)\n    scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(d_k)\n    \n    if mask is not None:\n        mask = mask.unsqueeze(1)\n        scores = scores.masked_fill(mask==0, -1e9)\n    # xong rồi thì chuẩn hóa bằng softmax\n    scores = F.softmax(scores, dim=-1)\n    \n    if dropout is not None:\n        scores = dropout(scores)\n    \n    output = torch.matmul(scores, v)\n    return output, scores\n\n# attention(torch.rand(32, 8, 30, 512), torch.rand(32, 8, 30, 512), torch.rand(32, 8, 30, 512)).shape","metadata":{"id":"2nJMcGuUNQId","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.346737Z","iopub.execute_input":"2024-12-13T09:39:41.347181Z","iopub.status.idle":"2024-12-13T09:39:41.358390Z","shell.execute_reply.started":"2024-12-13T09:39:41.347151Z","shell.execute_reply":"2024-12-13T09:39:41.357571Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, heads, d_model, dropout=0.1):\n        super().__init__()\n        assert d_model % heads == 0\n        \n        self.d_model = d_model\n        self.d_k = d_model//heads\n        self.h = heads\n        self.attn = None\n\n        # tạo ra 3 ma trận trọng số là q_linear, k_linear, v_linear như hình trên\n        self.q_linear = nn.Linear(d_model, d_model)\n        self.k_linear = nn.Linear(d_model, d_model)\n        self.v_linear = nn.Linear(d_model, d_model)\n        \n        self.dropout = nn.Dropout(dropout)\n        self.out = nn.Linear(d_model, d_model)\n    \n    def forward(self, q, k, v, mask=None):\n        \"\"\"\n        q: batch_size x seq_length x d_model\n        k: batch_size x seq_length x d_model\n        v: batch_size x seq_length x d_model\n        mask: batch_size x 1 x seq_length\n        output: batch_size x seq_length x d_model\n        \"\"\"\n        bs = q.size(0)\n        # nhân ma trận trọng số q_linear, k_linear, v_linear với dữ liệu đầu vào q, k, v \n        # ở bước encode các bạn lưu ý rằng q, k, v chỉ là một (xem hình trên)\n        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n        \n        q = q.transpose(1, 2)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n        \n        # tính attention score\n        scores, self.attn = attention(q, k, v, mask, self.dropout)\n        \n        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n        \n        output = self.out(concat)\n        return output\n\n# MultiHeadAttention(8, 512)(torch.rand(32, 30, 512), torch.rand(32, 30, 512), torch.rand(32, 30, 512)).shape","metadata":{"id":"ANQ4C3EENQIh","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.359261Z","iopub.execute_input":"2024-12-13T09:39:41.359521Z","iopub.status.idle":"2024-12-13T09:39:41.370482Z","shell.execute_reply.started":"2024-12-13T09:39:41.359495Z","shell.execute_reply":"2024-12-13T09:39:41.369756Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Residuals Connection và Normalization Layer\n\n\n","metadata":{"id":"uvOrq4-WPXYK"}},{"cell_type":"code","source":"class Norm(nn.Module):\n    def __init__(self, d_model, eps = 1e-6):\n        super().__init__()\n    \n        self.size = d_model\n        \n        # create two learnable parameters to calibrate normalisation\n        self.alpha = nn.Parameter(torch.ones(self.size))\n        self.bias = nn.Parameter(torch.zeros(self.size))\n        \n        self.eps = eps\n    \n    def forward(self, x):\n        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n        return norm","metadata":{"id":"n6-_9Hq-NQIk","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.371443Z","iopub.execute_input":"2024-12-13T09:39:41.371690Z","iopub.status.idle":"2024-12-13T09:39:41.384648Z","shell.execute_reply.started":"2024-12-13T09:39:41.371666Z","shell.execute_reply":"2024-12-13T09:39:41.383970Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n        super().__init__() \n    \n        # d_ff as a default to 2048\n        self.linear_1 = nn.Linear(d_model, d_ff)\n        self.dropout = nn.Dropout(dropout)\n        self.linear_2 = nn.Linear(d_ff, d_model)\n    \n    def forward(self, x):\n        x = self.dropout(F.relu(self.linear_1(x)))\n        x = self.linear_2(x)\n        return x","metadata":{"id":"H1ndbdMXNQIn","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.385600Z","iopub.execute_input":"2024-12-13T09:39:41.385939Z","iopub.status.idle":"2024-12-13T09:39:41.398365Z","shell.execute_reply.started":"2024-12-13T09:39:41.385903Z","shell.execute_reply":"2024-12-13T09:39:41.397666Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, d_model, heads, dropout=0.1):\n        super().__init__()\n        self.norm_1 = Norm(d_model)\n        self.norm_2 = Norm(d_model)\n        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n        self.ff = FeedForward(d_model, dropout=dropout)\n        self.dropout_1 = nn.Dropout(dropout)\n        self.dropout_2 = nn.Dropout(dropout)\n        \n    def forward(self, x, mask):\n        \"\"\"\n        x: batch_size x seq_length x d_model\n        mask: batch_size x 1 x seq_length\n        output: batch_size x seq_length x d_model\n        \"\"\"\n        \n        \n        x2 = self.norm_1(x)\n        # tính attention value, các bạn để ý q, k, v là giống nhau        \n        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n        x2 = self.norm_2(x)\n        x = x + self.dropout_2(self.ff(x2))\n        return x\n\n","metadata":{"id":"-Wwo91xDNQIq","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.399350Z","iopub.execute_input":"2024-12-13T09:39:41.399665Z","iopub.status.idle":"2024-12-13T09:39:41.409373Z","shell.execute_reply.started":"2024-12-13T09:39:41.399637Z","shell.execute_reply":"2024-12-13T09:39:41.408439Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Decoder","metadata":{}},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, d_model, heads, dropout=0.1):\n        super().__init__()\n        self.norm_1 = Norm(d_model)\n        self.norm_2 = Norm(d_model)\n        self.norm_3 = Norm(d_model)\n        \n        self.dropout_1 = nn.Dropout(dropout)\n        self.dropout_2 = nn.Dropout(dropout)\n        self.dropout_3 = nn.Dropout(dropout)\n        \n        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n        self.ff = FeedForward(d_model, dropout=dropout)\n\n    def forward(self, x, e_outputs, src_mask, trg_mask):\n        \"\"\"\n        x: batch_size x seq_length x d_model\n        e_outputs: batch_size x seq_length x d_model\n        src_mask: batch_size x 1 x seq_length\n        trg_mask: batch_size x 1 x seq_length\n        \"\"\"\n        x2 = self.norm_1(x)\n        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n        x2 = self.norm_2(x)\n        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n        x2 = self.norm_3(x)\n        x = x + self.dropout_3(self.ff(x2))\n        return x\n    \n","metadata":{"id":"6mDt2NPeNQIu","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.410678Z","iopub.execute_input":"2024-12-13T09:39:41.411361Z","iopub.status.idle":"2024-12-13T09:39:41.420860Z","shell.execute_reply.started":"2024-12-13T09:39:41.411322Z","shell.execute_reply":"2024-12-13T09:39:41.420048Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Cài đặt Encoder","metadata":{"id":"lk1c6NkYIeG8"}},{"cell_type":"code","source":"import copy\n\ndef get_clones(module, N):\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n\nclass Encoder(nn.Module):\n\n    def __init__(self, vocab_size, d_model, N, heads, dropout):\n        super().__init__()\n        self.N = N\n        self.embed = Embedder(vocab_size, d_model)\n        self.pe = PositionalEncoder(d_model, dropout=dropout)\n        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n        self.norm = Norm(d_model)\n        \n    def forward(self, src, mask):\n\n        x = self.embed(src)\n        x = self.pe(x)\n        for i in range(self.N):\n            x = self.layers[i](x, mask)\n        return self.norm(x)\n\n","metadata":{"id":"ZcU8nyvzNQIx","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.421762Z","iopub.execute_input":"2024-12-13T09:39:41.421992Z","iopub.status.idle":"2024-12-13T09:39:41.436650Z","shell.execute_reply.started":"2024-12-13T09:39:41.421968Z","shell.execute_reply":"2024-12-13T09:39:41.435811Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Cài đặt Decoder\nbao gồm N decoder layers","metadata":{"id":"Qip-E_TAIpmJ"}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, vocab_size, d_model, N, heads, dropout):\n        super().__init__()\n        self.N = N\n        self.embed = Embedder(vocab_size, d_model)\n        self.pe = PositionalEncoder(d_model, dropout=dropout)\n        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n        self.norm = Norm(d_model)\n    def forward(self, trg, e_outputs, src_mask, trg_mask):\n        \"\"\"\n        trg: batch_size x seq_length\n        e_outputs: batch_size x seq_length x d_model\n        src_mask: batch_size x 1 x seq_length\n        trg_mask: batch_size x 1 x seq_length\n        output: batch_size x seq_length x d_model\n        \"\"\"\n        x = self.embed(trg)\n        x = self.pe(x)\n        for i in range(self.N):\n            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n        return self.norm(x)\n    \n","metadata":{"id":"5lBRYMg_NQI0","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.437804Z","iopub.execute_input":"2024-12-13T09:39:41.438159Z","iopub.status.idle":"2024-12-13T09:39:41.453178Z","shell.execute_reply.started":"2024-12-13T09:39:41.438123Z","shell.execute_reply":"2024-12-13T09:39:41.452311Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Cài đặt Transformer \nbao gồm encoder và decoder","metadata":{"id":"gDVQGAaMI5UU"}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n        super().__init__()\n        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n        self.out = nn.Linear(d_model, trg_vocab)\n    def forward(self, src, trg, src_mask, trg_mask):\n        \"\"\"\n        src: batch_size x seq_length\n        trg: batch_size x seq_length\n        src_mask: batch_size x 1 x seq_length\n        trg_mask batch_size x 1 x seq_length\n        output: batch_size x seq_length x vocab_size\n        \"\"\"\n        e_outputs = self.encoder(src, src_mask)\n        \n        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n        output = self.out(d_output)\n        return output\n    \n","metadata":{"id":"DpxSCRILNQI3","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.454443Z","iopub.execute_input":"2024-12-13T09:39:41.454767Z","iopub.status.idle":"2024-12-13T09:39:41.468930Z","shell.execute_reply.started":"2024-12-13T09:39:41.454731Z","shell.execute_reply":"2024-12-13T09:39:41.468072Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# from torchtext import data\n# from torch.utils.data import DataLoader\n\n# class MyIterator(data.Iterator):\n#     def __init__(self, *args, num_workers=0, **kwargs):\n#         super().__init__(*args, **kwargs)\n#         self.num_workers = num_workers\n\n#     def create_batches(self):\n#         if self.train:\n#             def pool(d, random_shuffler):\n#                 for p in data.batch(d, self.batch_size * 100):\n#                     p_batch = data.batch(\n#                         sorted(p, key=self.sort_key),\n#                         self.batch_size, self.batch_size_fn)\n#                     for b in random_shuffler(list(p_batch)):\n#                         yield b\n\n#             # Sử dụng DataLoader với num_workers và collate_fn tùy chỉnh\n#             dataset = list(self.data())  # Chuyển dữ liệu thành danh sách\n#             dataloader = DataLoader(\n#                 dataset,\n#                 batch_size=self.batch_size * 100,\n#                 shuffle=True,  # Hoặc False nếu không cần xáo trộn\n#                 num_workers=self.num_workers,\n#                 collate_fn=self.collate_fn  # Hàm collate tùy chỉnh\n#             )\n\n#             self.batches = pool(dataloader, self.random_shuffler)\n\n#         else:\n#             self.batches = []\n#             for b in data.batch(self.data(), self.batch_size, self.batch_size_fn):\n#                 self.batches.append(sorted(b, key=self.sort_key))\n\n#     def collate_fn(self, batch):\n#         \"\"\"Chuyển đổi các Example thành tensor hoặc định dạng phù hợp.\"\"\"\n#         # Xử lý batch thành các tensor hoặc cấu trúc cần thiết\n#         fields = self.dataset.fields\n#         collated = {name: [getattr(x, name) for x in batch] for name in fields}\n#         for name, field in fields.items():\n#             if field is not None and field.batch_first:\n#                 collated[name] = field.process(collated[name])\n#         return collated\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.473993Z","iopub.execute_input":"2024-12-13T09:39:41.474482Z","iopub.status.idle":"2024-12-13T09:39:41.484493Z","shell.execute_reply.started":"2024-12-13T09:39:41.474444Z","shell.execute_reply":"2024-12-13T09:39:41.483764Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from torchtext import data\n\nclass MyIterator(data.Iterator):\n    def create_batches(self):\n        if self.train:\n            def pool(d, random_shuffler):\n                for p in data.batch(d, self.batch_size * 100):\n                    p_batch = data.batch(\n                        sorted(p, key=self.sort_key),\n                        self.batch_size, self.batch_size_fn)\n                    for b in random_shuffler(list(p_batch)):\n                        yield b\n            self.batches = pool(self.data(), self.random_shuffler)\n            \n        else:\n            self.batches = []\n            for b in data.batch(self.data(), self.batch_size,\n                                          self.batch_size_fn):\n                self.batches.append(sorted(b, key=self.sort_key))\n\nglobal max_src_in_batch, max_tgt_in_batch\n\ndef batch_size_fn(new, count, sofar):\n    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n    global max_src_in_batch, max_tgt_in_batch\n    if count == 1:\n        max_src_in_batch = 0\n        max_tgt_in_batch = 0\n    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n    src_elements = count * max_src_in_batch\n    tgt_elements = count * max_tgt_in_batch\n    return max(src_elements, tgt_elements)","metadata":{"id":"M5tvzW9jNQI6","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.486025Z","iopub.execute_input":"2024-12-13T09:39:41.486311Z","iopub.status.idle":"2024-12-13T09:39:41.665635Z","shell.execute_reply.started":"2024-12-13T09:39:41.486271Z","shell.execute_reply":"2024-12-13T09:39:41.664737Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\ndef nopeak_mask(size, device):\n    np_mask = np.triu(np.ones((1, size, size)),\n    k=1).astype('uint8')\n    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n    np_mask = np_mask.to(device)\n    \n    return np_mask\n\ndef create_masks(src, trg, src_pad, trg_pad, device):\n    src_mask = (src != src_pad).unsqueeze(-2)\n\n    if trg is not None:\n        trg_mask = (trg != trg_pad).unsqueeze(-2)\n        size = trg.size(1) # get seq_len for matrix\n        np_mask = nopeak_mask(size, device)\n        if trg.is_cuda:\n            np_mask.cuda()\n        trg_mask = trg_mask & np_mask\n        \n    else:\n        trg_mask = None\n    return src_mask, trg_mask","metadata":{"id":"NkBjLH96NQI8","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.666595Z","iopub.execute_input":"2024-12-13T09:39:41.666859Z","iopub.status.idle":"2024-12-13T09:39:41.672813Z","shell.execute_reply.started":"2024-12-13T09:39:41.666833Z","shell.execute_reply":"2024-12-13T09:39:41.671988Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from nltk.corpus import wordnet\nimport re\n\ndef get_synonym(word, SRC):\n    syns = wordnet.synsets(word)\n    for s in syns:\n        for l in s.lemmas():\n            if SRC.vocab.stoi[l.name()] != 0:\n                return SRC.vocab.stoi[l.name()]\n            \n    return 0\n\ndef multiple_replace(dict, text):\n  # Create a regular expression  from the dictionary keys\n  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n\n  # For each match, look-up corresponding value in dictionary\n  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text) ","metadata":{"id":"9YoUVx4xjEb7","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.673869Z","iopub.execute_input":"2024-12-13T09:39:41.674148Z","iopub.status.idle":"2024-12-13T09:39:41.688144Z","shell.execute_reply.started":"2024-12-13T09:39:41.674123Z","shell.execute_reply":"2024-12-13T09:39:41.687446Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def init_vars(src, model, SRC, TRG, device, k, max_len):\n\n    init_tok = TRG.vocab.stoi['<sos>']\n    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n\n    # tính sẵn output của encoder \n    e_output = model.encoder(src, src_mask)\n    \n    outputs = torch.LongTensor([[init_tok]])\n    \n    outputs = outputs.to(device)\n    \n    trg_mask = nopeak_mask(1, device)\n    # dự đoán kí tự đầu tiên\n    out = model.out(model.decoder(outputs,\n    e_output, src_mask, trg_mask))\n    out = F.softmax(out, dim=-1)\n    \n    probs, ix = out[:, -1].data.topk(k)\n    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n    \n    outputs = torch.zeros(k, max_len).long()\n    outputs = outputs.to(device)\n    outputs[:, 0] = init_tok\n    outputs[:, 1] = ix[0]\n    \n    e_outputs = torch.zeros(k, e_output.size(-2),e_output.size(-1))\n   \n    e_outputs = e_outputs.to(device)\n    e_outputs[:, :] = e_output[0]\n    \n    return outputs, e_outputs, log_scores\n\ndef k_best_outputs(outputs, out, log_scores, i, k):\n    \n    probs, ix = out[:, -1].data.topk(k)\n    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n    k_probs, k_ix = log_probs.view(-1).topk(k)\n    \n    row = k_ix // k\n    col = k_ix % k\n\n    outputs[:, :i] = outputs[row, :i]\n    outputs[:, i] = ix[row, col]\n\n    log_scores = k_probs.unsqueeze(0)\n    \n    return outputs, log_scores\n\ndef beam_search(src, model, SRC, TRG, device, k, max_len):    \n\n    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, device, k, max_len)\n    eos_tok = TRG.vocab.stoi['<eos>']\n    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n    ind = None\n    for i in range(2, max_len):\n    \n        trg_mask = nopeak_mask(i, device)\n\n        out = model.out(model.decoder(outputs[:,:i],\n        e_outputs, src_mask, trg_mask))\n\n        out = F.softmax(out, dim=-1)\n    \n        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, k)\n        \n        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).cuda()\n        for vec in ones:\n            i = vec[0]\n            if sentence_lengths[i]==0: # First end symbol has not been found yet\n                sentence_lengths[i] = vec[1] # Position of first end symbol\n\n        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n\n        if num_finished_sentences == k:\n            alpha = 0.7\n            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n            _, ind = torch.max(log_scores * div, 1)\n            ind = ind.data[0]\n            break\n    \n    if ind is None:\n        \n        length = (outputs[0]==eos_tok).nonzero()[0] if len((outputs[0]==eos_tok).nonzero()) > 0 else -1\n        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n    \n    else:\n        length = (outputs[ind]==eos_tok).nonzero()[0]\n        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])","metadata":{"id":"1IJpUEIMgMbw","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.689322Z","iopub.execute_input":"2024-12-13T09:39:41.689580Z","iopub.status.idle":"2024-12-13T09:39:41.704936Z","shell.execute_reply.started":"2024-12-13T09:39:41.689555Z","shell.execute_reply":"2024-12-13T09:39:41.704310Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# def translate_sentence(sentence, model, SRC, TRG, device, k, max_len):\n#     \"\"\"Dịch một câu sử dụng beamsearch\n#     \"\"\"\n#     model.eval()\n#     indexed = []\n#     sentence = SRC.preprocess(sentence)\n    \n#     for tok in sentence:\n#         if SRC.vocab.stoi[tok] != SRC.vocab.stoi['<eos>']:\n#             indexed.append(SRC.vocab.stoi[tok])\n#         else:\n#             indexed.append(get_synonym(tok, SRC))\n    \n#     sentence = Variable(torch.LongTensor([indexed]))\n    \n#     sentence = sentence.to(device)\n    \n#     sentence = beam_search(sentence, model, SRC, TRG, device, k, max_len)\n\n#     return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)","metadata":{"id":"s-AFuSOIhi7X","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.705925Z","iopub.execute_input":"2024-12-13T09:39:41.706191Z","iopub.status.idle":"2024-12-13T09:39:41.718439Z","shell.execute_reply.started":"2024-12-13T09:39:41.706167Z","shell.execute_reply":"2024-12-13T09:39:41.717835Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def translate_sentence(sentence, model, SRC, TRG, device, k, max_len):\n    model.eval()\n    tokens = SRC.preprocess(sentence)  # Token hóa câu\n    indexed = []\n\n    for tok in tokens:\n        if tok in SRC.vocab.stoi:  # Kiểm tra từ trong từ điển\n            indexed.append(SRC.vocab.stoi[tok])\n        else:\n            indexed.append(SRC.vocab.stoi[\"<unk>\"])  # Dùng <unk> nếu từ không có trong từ điển\n\n    # Chuyển danh sách sang tensor\n    sentence_tensor = torch.LongTensor([indexed]).to(device)\n\n    # Áp dụng thuật toán tìm kiếm (ví dụ: beam search)\n    prediction = beam_search(sentence_tensor, model, SRC, TRG, device, k, max_len)\n\n    return prediction\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.719431Z","iopub.execute_input":"2024-12-13T09:39:41.719683Z","iopub.status.idle":"2024-12-13T09:39:41.729126Z","shell.execute_reply.started":"2024-12-13T09:39:41.719658Z","shell.execute_reply":"2024-12-13T09:39:41.728489Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import spacy\nimport re\n\nclass tokenize(object):\n    \n    def __init__(self, lang):\n        self.nlp = spacy.load(lang)\n            \n    def tokenizer(self, sentence):\n        sentence = re.sub(\n        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n        sentence = re.sub(r\"\\,+\", \",\", sentence)\n        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n        sentence = sentence.lower()\n        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]","metadata":{"id":"4Uee4YaQNQI_","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:41.730285Z","iopub.execute_input":"2024-12-13T09:39:41.730632Z","iopub.status.idle":"2024-12-13T09:39:42.985583Z","shell.execute_reply.started":"2024-12-13T09:39:41.730596Z","shell.execute_reply":"2024-12-13T09:39:42.984909Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Data loader\nSử dụng torchtext để load dữ liệu nhanh chóng","metadata":{"id":"x2jMF9lzQ4a8"}},{"cell_type":"code","source":"import os\nimport dill as pickle\nimport pandas as pd\n\n# def read_data(src_file, trg_file):\n#     src_data = open(src_file).read().strip().split('\\n')\n\n#     trg_data = open(trg_file).read().strip().split('\\n')\n \n#     return src_data, trg_data\ndef read_data(file_path):\n    src_data = []\n    trg_data = []\n\n    # Đọc file\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        for line in file:\n            # Loại bỏ khoảng trắng ở đầu/cuối và tách câu bằng tab\n            parts = line.strip().split(\"\\t\")\n            if len(parts) == 2:  # Đảm bảo mỗi dòng có đủ 2 phần\n                src_data.append(parts[0])  # Câu tiếng Anh\n                trg_data.append(parts[1])  # Câu tiếng Việt\n    \n    return src_data, trg_data\n\ndef create_fields(src_lang, trg_lang):\n    \n    print(\"loading spacy tokenizers...\")\n    \n    t_src = tokenize(src_lang)\n    t_trg = tokenize(trg_lang)\n\n    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n        \n    return SRC, TRG\n\ndef create_dataset(src_data, trg_data, max_strlen, batchsize, device, SRC, TRG, istrain=True):\n\n    print(\"creating dataset and iterator... \")\n\n    raw_data = {'src' : [line for line in src_data], 'trg': [line for line in trg_data]}\n    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n    \n    mask = (df['src'].str.count(' ') < max_strlen) & (df['trg'].str.count(' ') < max_strlen)\n    df = df.loc[mask]\n\n    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n    \n    data_fields = [('src', SRC), ('trg', TRG)]\n    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n\n    train_iter = MyIterator(train, batch_size=batchsize, device=device,\n                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n                        batch_size_fn=batch_size_fn, train=istrain, shuffle=True)\n    \n    os.remove('translate_transformer_temp.csv')\n    \n    if istrain:\n        SRC.build_vocab(train)\n        TRG.build_vocab(train)\n\n    return train_iter\n","metadata":{"id":"_uVO0yr_NQJC","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:42.986630Z","iopub.execute_input":"2024-12-13T09:39:42.986984Z","iopub.status.idle":"2024-12-13T09:39:43.271037Z","shell.execute_reply.started":"2024-12-13T09:39:42.986957Z","shell.execute_reply":"2024-12-13T09:39:43.270360Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def step(model, optimizer,batch, criterion):\n    \"\"\"\n    Một lần cập nhật mô hình\n    \"\"\"\n    model.train()\n    \n    src = batch.src.transpose(0,1).cuda()\n    trg = batch.trg.transpose(0,1).cuda()\n    trg_input = trg[:, :-1]\n    src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n    preds = model(src, trg_input, src_mask, trg_mask)\n\n    ys = trg[:, 1:].contiguous().view(-1)\n\n    optimizer.zero_grad()\n    loss = criterion(preds.view(-1, preds.size(-1)), ys)\n    loss.backward()\n    optimizer.step_and_update_lr()\n    \n    loss = loss.item()\n    \n    return loss    ","metadata":{"id":"l4POJRxdNQJF","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:43.272082Z","iopub.execute_input":"2024-12-13T09:39:43.272496Z","iopub.status.idle":"2024-12-13T09:39:43.277920Z","shell.execute_reply.started":"2024-12-13T09:39:43.272467Z","shell.execute_reply":"2024-12-13T09:39:43.277127Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def validiate(model, valid_iter, criterion):\n    \"\"\" Tính loss trên tập validation\n    \"\"\"\n    model.eval()\n    \n    with torch.no_grad():\n        total_loss = []\n        for batch in valid_iter:\n            src = batch.src.transpose(0,1).cuda()\n            trg = batch.trg.transpose(0,1).cuda()\n            trg_input = trg[:, :-1]\n            src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n            preds = model(src, trg_input, src_mask, trg_mask)\n\n            ys = trg[:, 1:].contiguous().view(-1)\n            \n            loss = criterion(preds.view(-1, preds.size(-1)), ys)\n            \n            loss = loss.item()\n            \n            total_loss.append(loss)\n        \n    avg_loss = np.mean(total_loss)\n    \n    return avg_loss","metadata":{"id":"c5sPA-k_NQJI","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:43.278952Z","iopub.execute_input":"2024-12-13T09:39:43.279254Z","iopub.status.idle":"2024-12-13T09:39:43.294624Z","shell.execute_reply.started":"2024-12-13T09:39:43.279229Z","shell.execute_reply":"2024-12-13T09:39:43.293958Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Optimizer\n\n","metadata":{"id":"QX4b6LLN47qC"}},{"cell_type":"code","source":"class ScheduledOptim():\n    '''A simple wrapper class for learning rate scheduling'''\n\n    def __init__(self, optimizer, init_lr, d_model, n_warmup_steps):\n        self._optimizer = optimizer\n        self.init_lr = init_lr\n        self.d_model = d_model\n        self.n_warmup_steps = n_warmup_steps\n        self.n_steps = 0\n\n\n    def step_and_update_lr(self):\n        \"Step with the inner optimizer\"\n        self._update_learning_rate()\n        self._optimizer.step()\n\n\n    def zero_grad(self):\n        \"Zero out the gradients with the inner optimizer\"\n        self._optimizer.zero_grad()\n\n\n    def _get_lr_scale(self):\n        d_model = self.d_model\n        n_steps, n_warmup_steps = self.n_steps, self.n_warmup_steps\n        return (d_model ** -0.5) * min(n_steps ** (-0.5), n_steps * n_warmup_steps ** (-1.5))\n\n    def state_dict(self):\n        optimizer_state_dict = {\n            'init_lr':self.init_lr,\n            'd_model':self.d_model,\n            'n_warmup_steps':self.n_warmup_steps,\n            'n_steps':self.n_steps,\n            '_optimizer':self._optimizer.state_dict(),\n        }\n        \n        return optimizer_state_dict\n    \n    def load_state_dict(self, state_dict):\n        self.init_lr = state_dict['init_lr']\n        self.d_model = state_dict['d_model']\n        self.n_warmup_steps = state_dict['n_warmup_steps']\n        self.n_steps = state_dict['n_steps']\n        \n        self._optimizer.load_state_dict(state_dict['_optimizer'])\n        \n    def _update_learning_rate(self):\n        ''' Learning rate scheduling per step '''\n\n        self.n_steps += 1\n        lr = self.init_lr * self._get_lr_scale()\n\n        for param_group in self._optimizer.param_groups:\n            param_group['lr'] = lr","metadata":{"id":"OW8pRq91rwJR","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:43.295718Z","iopub.execute_input":"2024-12-13T09:39:43.296299Z","iopub.status.idle":"2024-12-13T09:39:43.310270Z","shell.execute_reply.started":"2024-12-13T09:39:43.296260Z","shell.execute_reply":"2024-12-13T09:39:43.309519Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Label Smoothing\n\n\n","metadata":{"id":"TKJoYats5LYn"}},{"cell_type":"code","source":"class LabelSmoothingLoss(nn.Module):\n    def __init__(self, classes, padding_idx, smoothing=0.0, dim=-1):\n        super(LabelSmoothingLoss, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.cls = classes\n        self.dim = dim\n        self.padding_idx = padding_idx\n\n    def forward(self, pred, target):\n        pred = pred.log_softmax(dim=self.dim)\n        with torch.no_grad():\n            # true_dist = pred.data.clone()\n            true_dist = torch.zeros_like(pred)\n            true_dist.fill_(self.smoothing / (self.cls - 2))\n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n            true_dist[:, self.padding_idx] = 0\n            mask = torch.nonzero(target.data == self.padding_idx, as_tuple=False)\n            if mask.dim() > 0:\n                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n            \n        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))","metadata":{"id":"LHGeSHThtlj-","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:43.311140Z","iopub.execute_input":"2024-12-13T09:39:43.311419Z","iopub.status.idle":"2024-12-13T09:39:43.323610Z","shell.execute_reply.started":"2024-12-13T09:39:43.311387Z","shell.execute_reply":"2024-12-13T09:39:43.322894Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from torchtext.data.metrics import bleu_score\n\n# def bleu(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen):\n#     pred_sents = []\n#     for sentence in valid_src_data:\n#         pred_trg = translate_sentence(sentence, model, SRC, TRG, device, k, max_strlen)\n#         pred_sents.append(pred_trg)\n    \n#     pred_sents = [TRG.preprocess(sent) for sent in pred_sents]\n#     trg_sents = [[sent.split()] for sent in valid_trg_data]\n    \n#     return bleu_score(pred_sents, trg_sents)","metadata":{"id":"Sg257Gk_Kzzw","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:43.324449Z","iopub.execute_input":"2024-12-13T09:39:43.324689Z","iopub.status.idle":"2024-12-13T09:39:43.337487Z","shell.execute_reply.started":"2024-12-13T09:39:43.324664Z","shell.execute_reply":"2024-12-13T09:39:43.336685Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"opt = {\n    'train_src_data':'/kaggle/input/multi30k-english-vietnamese/train',\n    'valid_src_data':'/kaggle/input/multi30k-english-vietnamese/validation',\n    'test_src_data' :'/kaggle/input/multi30k-english-vietnamese/test',\n    'src_lang':'en',\n    'trg_lang':'en',#'vi_spacy_model',\n    'max_strlen':200,\n    'batchsize':10000,\n    'device':'cuda',\n    'd_model': 512,\n    'n_layers': 6,\n    'heads': 8,\n    'dropout': 0.1,\n    'lr':0.0001,\n    'epochs':100,\n    'printevery': 200,\n    'k':5,\n}","metadata":{"id":"Nhgu-SPTNQJL","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:43.338392Z","iopub.execute_input":"2024-12-13T09:39:43.338726Z","iopub.status.idle":"2024-12-13T09:39:43.347473Z","shell.execute_reply.started":"2024-12-13T09:39:43.338690Z","shell.execute_reply":"2024-12-13T09:39:43.346740Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:43.348569Z","iopub.execute_input":"2024-12-13T09:39:43.349202Z","iopub.status.idle":"2024-12-13T09:39:55.432328Z","shell.execute_reply.started":"2024-12-13T09:39:43.349162Z","shell.execute_reply":"2024-12-13T09:39:55.431172Z"}},"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import spacy\nimport re\n\nclass tokenize(object):\n\n    def __init__(self, lang):\n        # Load the English language model by its full name\n        if lang == 'en':\n            self.nlp = spacy.load(\"en_core_web_sm\") \n        else:\n            self.nlp = spacy.load(lang)\n\n    def tokenizer(self, sentence):\n        sentence = re.sub(\n        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n        sentence = re.sub(r\"\\,+\", \",\", sentence)\n        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n        sentence = sentence.lower()\n        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:55.433816Z","iopub.execute_input":"2024-12-13T09:39:55.434270Z","iopub.status.idle":"2024-12-13T09:39:55.441251Z","shell.execute_reply.started":"2024-12-13T09:39:55.434235Z","shell.execute_reply":"2024-12-13T09:39:55.440288Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"train_src_data, train_trg_data = read_data(opt['train_src_data'])\nvalid_src_data, valid_trg_data = read_data(opt['valid_src_data'])\ntest_src_data, test_trg_data = read_data(opt['test_src_data'])\nSRC, TRG = create_fields(opt['src_lang'], opt['trg_lang'])\ntrain_iter = create_dataset(train_src_data, train_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=True)\nvalid_iter = create_dataset(valid_src_data, valid_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=False)","metadata":{"id":"IBotIB8pNQJU","outputId":"12e472e9-08b7-451b-f89f-15d1c6df2e0b","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:39:55.442328Z","iopub.execute_input":"2024-12-13T09:39:55.442582Z","iopub.status.idle":"2024-12-13T09:40:01.636501Z","shell.execute_reply.started":"2024-12-13T09:39:55.442556Z","shell.execute_reply":"2024-12-13T09:40:01.635813Z"}},"outputs":[{"name":"stdout","text":"loading spacy tokenizers...\ncreating dataset and iterator... \ncreating dataset and iterator... \n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"src_pad = SRC.vocab.stoi['<pad>']\ntrg_pad = TRG.vocab.stoi['<pad>']","metadata":{"id":"Gnw9xrJeNQJX","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:40:01.637479Z","iopub.execute_input":"2024-12-13T09:40:01.637756Z","iopub.status.idle":"2024-12-13T09:40:01.642065Z","shell.execute_reply.started":"2024-12-13T09:40:01.637728Z","shell.execute_reply":"2024-12-13T09:40:01.640989Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\n\nfor p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n\nmodel = model.to(opt['device'])","metadata":{"id":"5RccNL8VNQJd","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:40:01.643125Z","iopub.execute_input":"2024-12-13T09:40:01.643368Z","iopub.status.idle":"2024-12-13T09:40:03.760873Z","shell.execute_reply.started":"2024-12-13T09:40:01.643343Z","shell.execute_reply":"2024-12-13T09:40:03.759717Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"\noptimizer = ScheduledOptim(\n        torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n        0.2, opt['d_model'], 4000)\n\ncriterion = LabelSmoothingLoss(len(TRG.vocab), padding_idx=trg_pad, smoothing=0.1)","metadata":{"id":"12debLGiNQJg","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:40:03.762289Z","iopub.execute_input":"2024-12-13T09:40:03.762580Z","iopub.status.idle":"2024-12-13T09:40:04.498836Z","shell.execute_reply.started":"2024-12-13T09:40:03.762551Z","shell.execute_reply":"2024-12-13T09:40:04.498145Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"!pip install -q nltk==3.9b1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:40:04.499872Z","iopub.execute_input":"2024-12-13T09:40:04.500332Z","iopub.status.idle":"2024-12-13T09:40:14.244496Z","shell.execute_reply.started":"2024-12-13T09:40:04.500303Z","shell.execute_reply":"2024-12-13T09:40:14.243588Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9b1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"test_sentence = \"A group of people sitting in a park.\"\nresult = translate_sentence(test_sentence, model, SRC, TRG, opt['device'], k=5, max_len=50)\nprint(\"Dịch thử:\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:58:49.900611Z","iopub.execute_input":"2024-12-13T09:58:49.901223Z","iopub.status.idle":"2024-12-13T09:58:50.051604Z","shell.execute_reply.started":"2024-12-13T09:58:49.901185Z","shell.execute_reply":"2024-12-13T09:58:50.050814Z"}},"outputs":[{"name":"stdout","text":"Dịch thử: một nhóm người đang ngồi trong công viên .\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import wordnet\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # Tải tài nguyên bổ trợ\n\ndef get_synonym(word, SRC):\n    try:\n        syns = wordnet.synsets(word)\n    except LookupError:\n        return word  # Nếu không tải được tài nguyên, trả về từ gốc\n\n    for s in syns:\n        for l in s.lemmas():\n            if l.name() in SRC.vocab.stoi:\n                return SRC.vocab.stoi[l.name()]\n    return SRC.vocab.stoi.get(word, SRC.vocab.stoi[\"<unk>\"])\n\ndef bleu(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen):\n    pred_sents = []\n    for sentence in valid_src_data:\n        pred_trg = translate_sentence(sentence, model, SRC, TRG, device, k, max_strlen)\n        pred_sents.append(pred_trg)\n\n    pred_sents = [TRG.preprocess(sent) for sent in pred_sents]\n    trg_sents = [[sent.split()] for sent in valid_trg_data]\n\n    return bleu_score(pred_sents, trg_sents)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:40:15.410023Z","iopub.execute_input":"2024-12-13T09:40:15.410383Z","iopub.status.idle":"2024-12-13T09:40:15.588305Z","shell.execute_reply.started":"2024-12-13T09:40:15.410343Z","shell.execute_reply":"2024-12-13T09:40:15.587390Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"import time\n\nfor epoch in range(opt['epochs']):\n    total_loss = 0\n    \n    for i, batch in enumerate(train_iter): \n        s = time.time()\n        loss = step(model, optimizer, batch, criterion)\n        \n        total_loss += loss\n        \n        if (i + 1) % opt['printevery'] == 0:\n            avg_loss = total_loss/opt['printevery']\n            print('epoch: {:03d} - iter: {:05d} - train loss: {:.4f} - time: {:.4f}'.format(epoch, i, avg_loss, time.time()- s))\n            total_loss = 0\n\n    s = time.time()\n    valid_loss = validiate(model, valid_iter, criterion)\n    bleuscore = bleu(valid_src_data[:500], valid_trg_data[:500], model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n    print('epoch: {:03d} - iter: {:05d} - valid loss: {:.4f} - bleu score: {:.4f} - time: {:.4f}'.format(epoch, i, valid_loss, bleuscore, time.time() - s))\n    ","metadata":{"id":"JeZqfQPANQJl","outputId":"1ac374a6-7ce3-46da-fe7e-47a8463148ed","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rouge(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen):\n    pred_sents = []\n    rouge = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n    score = []\n    score_rouge1 = 0\n    for sentence, trg_sents in zip(valid_src_data, valid_trg_data):\n        pred_trg = translate_sentence(sentence, model, SRC, TRG, device, k, max_strlen)\n        # pred_sents.append(pred_trg)\n        scores = rouge.score(trg_sents, pred_trg)\n        score_rouge1 += scores['rouge1'].fmeasure  # Sử dụng fmeasure cho ROUGE-1\n    \n    return score_rouge1/len(valid_src_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T10:11:30.331918Z","iopub.execute_input":"2024-12-13T10:11:30.332383Z","iopub.status.idle":"2024-12-13T10:11:30.338765Z","shell.execute_reply.started":"2024-12-13T10:11:30.332333Z","shell.execute_reply":"2024-12-13T10:11:30.337804Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# rouge_score = rouge(valid_src_data, valid_trg_data, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n# bleu_score = bleu(valid_src_data, valid_trg_data, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\n\ndef save_scores_to_tsv(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen, filename):\n    rouge_score = rouge(valid_src_data, valid_trg_data, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n    bleu_score = bleu(valid_src_data, valid_trg_data, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n\n    scores = {\n        'ROUGE Score': rouge_score,\n        'BLEU Score': bleu_score\n    }\n    print(scores)\n    with open(filename, mode='w', newline='') as file:\n        writer = csv.writer(file, delimiter='\\t')\n        writer.writerow(scores.keys())  \n        writer.writerow(scores.values())  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T10:43:21.650705Z","iopub.execute_input":"2024-12-13T10:43:21.651084Z","iopub.status.idle":"2024-12-13T10:43:21.657165Z","shell.execute_reply.started":"2024-12-13T10:43:21.651048Z","shell.execute_reply":"2024-12-13T10:43:21.656295Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"save_scores_to_tsv(valid_src_data, valid_trg_data, model, SRC,TRG, opt['device'], opt['k'], opt['max_strlen'], 'scores.tsv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T10:43:23.625063Z","iopub.execute_input":"2024-12-13T10:43:23.625733Z","iopub.status.idle":"2024-12-13T10:51:28.442669Z","shell.execute_reply.started":"2024-12-13T10:43:23.625696Z","shell.execute_reply":"2024-12-13T10:51:28.441815Z"}},"outputs":[{"name":"stdout","text":"{'ROUGE Score': 0.8825721034683567, 'BLEU Score': 0.5271968841552734}\n","output_type":"stream"}],"execution_count":112},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model_weights.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:42:15.702616Z","iopub.status.idle":"2024-12-13T09:42:15.702900Z","shell.execute_reply.started":"2024-12-13T09:42:15.702767Z","shell.execute_reply":"2024-12-13T09:42:15.702782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentence='My family was not poor , and myself , I had never experienced hunger .'\ntrans_sent = translate_sentence(sentence, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\ntrans_sent","metadata":{"id":"0CwtdJeUNQJo","outputId":"190c4a93-436a-4b00-832b-ae8f4c183fe4","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T10:53:08.060877Z","iopub.execute_input":"2024-12-13T10:53:08.061509Z","iopub.status.idle":"2024-12-13T10:53:08.319731Z","shell.execute_reply.started":"2024-12-13T10:53:08.061470Z","shell.execute_reply":"2024-12-13T10:53:08.318866Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"'gia đình không phải , nghèo đói và cầm tờ rơi , tôi đã ngủ thiếp đi .'"},"metadata":{}}],"execution_count":113},{"cell_type":"markdown","source":"# Visualize","metadata":{"id":"A7UYpmmqj31m"}},{"cell_type":"code","source":"import seaborn\nimport matplotlib.pyplot as plt\n\ndef draw(data, x, y, ax):\n    seaborn.heatmap(data, \n                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n                    cbar=False, ax=ax, annot=False)","metadata":{"id":"vHeTea84_bDP","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:42:15.705633Z","iopub.status.idle":"2024-12-13T09:42:15.705952Z","shell.execute_reply.started":"2024-12-13T09:42:15.705802Z","shell.execute_reply":"2024-12-13T09:42:15.705819Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Encoder\n","metadata":{"id":"izoCgA3zNR2i"}},{"cell_type":"code","source":"sent = SRC.preprocess(sentence)\n\nfor layer in range(1, 6, 2):\n    fig, axs = plt.subplots(1,4, figsize=(30, 15))\n    print(\"Encoder Layer\", layer+1)\n    for h in range(4):\n        draw(model.encoder.layers[layer].attn.attn[0, h].data.cpu(), \n            sent, sent if h ==0 else [], ax=axs[h])\n    plt.show()","metadata":{"id":"rV57CMAZ9XR8","outputId":"f88e1760-07c7-4d0a-a557-e78f24cd3a75","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:42:15.706850Z","iopub.status.idle":"2024-12-13T09:42:15.707165Z","shell.execute_reply.started":"2024-12-13T09:42:15.706988Z","shell.execute_reply":"2024-12-13T09:42:15.707002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Decoder\n* self attention: giá trị attention khi mô hình decoder mã hóa câu đích lúc dịch\n* src attention: giá trị attention khi mô hình decoder sử dụng câu src","metadata":{"id":"0M4_pHeqNkr1"}},{"cell_type":"code","source":"trg_sent = ['<sos>'] + TRG.preprocess(trans_sent)\n\nfor layer in range(1, 6, 2):\n    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n    print(\"Decoder Self Layer\", layer+1)\n    for h in range(4):\n        draw(model.decoder.layers[layer].attn_1.attn[0, h].data[:len(trg_sent), :len(trg_sent)].cpu(), \n            trg_sent, trg_sent if h ==0 else [], ax=axs[h])\n    plt.show()\n    print(\"Decoder Src Layer\", layer+1)\n    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n    for h in range(4):\n        draw(model.decoder.layers[layer].attn_2.attn[0, h].data[:len(trg_sent), :len(sent)].cpu(), \n            sent, trg_sent if h ==0 else [], ax=axs[h])\n    plt.show()","metadata":{"id":"miQbM9X9-FD7","outputId":"36fd4cb6-f811-4352-edd3-a8d6ce0648f7","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:42:15.708441Z","iopub.status.idle":"2024-12-13T09:42:15.708746Z","shell.execute_reply.started":"2024-12-13T09:42:15.708602Z","shell.execute_reply":"2024-12-13T09:42:15.708618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/test/transformers/default/1/model_weights.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:42:23.071184Z","iopub.execute_input":"2024-12-13T09:42:23.071859Z","iopub.status.idle":"2024-12-13T09:42:40.881702Z","shell.execute_reply.started":"2024-12-13T09:42:23.071823Z","shell.execute_reply":"2024-12-13T09:42:40.880675Z"}},"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1Ty1bGrd0sCwEqXhsoViCUaNKa3lFwmPH\nFrom (redirected): https://drive.google.com/uc?id=1Ty1bGrd0sCwEqXhsoViCUaNKa3lFwmPH&confirm=t&uuid=ce0d5f56-ccfc-48bf-af9f-72e0566a3ca5\nTo: /kaggle/working/transformer.pth\n100%|█████████████████████████████████████████| 348M/348M [00:01<00:00, 181MB/s]\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_23/899766779.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/input/test/transformers/default/1/model_weights.pth'))\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":42}]}